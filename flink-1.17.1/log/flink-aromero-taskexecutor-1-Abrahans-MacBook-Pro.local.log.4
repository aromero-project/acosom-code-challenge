2023-08-23 18:59:58,640 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: localhost.
2023-08-23 18:59:58,775 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2023-08-23 18:59:59,887 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-08-23 18:59:59,919 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2023-08-23 18:59:59,920 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-08-23 19:00:00,095 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@localhost:50986]
2023-08-23 19:00:00,194 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@localhost:50986
2023-08-23 19:00:00,211 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using working directory: WorkingDirectory(/var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/tm_localhost:50986-bfdf18)
2023-08-23 19:00:00,218 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2023-08-23 19:00:00,223 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2023-08-23 19:00:00,242 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-08-23 19:00:00,247 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2023-08-23 19:00:00,248 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-08-23 19:00:00,273 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@localhost:50987]
2023-08-23 19:00:00,284 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@localhost:50987
2023-08-23 19:00:00,299 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_localhost:50986-bfdf18 .
2023-08-23 19:00:00,314 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/tm_localhost:50986-bfdf18/blobStorage
2023-08-23 19:00:00,322 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/tm_localhost:50986-bfdf18/blobStorage
2023-08-23 19:00:00,326 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2023-08-23 19:00:00,327 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2023-08-23 19:00:00,330 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2023-08-23 19:00:00,331 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2023-08-23 19:00:00,331 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2023-08-23 19:00:00,331 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2023-08-23 19:00:00,331 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2023-08-23 19:00:00,331 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2023-08-23 19:00:00,332 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2023-08-23 19:00:00,332 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2023-08-23 19:00:00,332 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2023-08-23 19:00:00,332 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2023-08-23 19:00:00,332 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2023-08-23 19:00:00,332 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: localhost:50986-bfdf18
2023-08-23 19:00:00,355 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T': total 465 GB, usable 371 GB (79.78% usable)
2023-08-23 19:00:00,359 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/flink-io-f1dea98e-f946-4373-b17b-4a5cc20b1f34
2023-08-23 19:00:00,366 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: localhost/127.0.0.1, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 1 (manual), number of client threads: 1 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2023-08-23 19:00:00,419 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/flink-netty-shuffle-255d34a8-742f-4f35-a8bf-f3f8ab3988ab
2023-08-23 19:00:00,496 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2023-08-23 19:00:00,510 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2023-08-23 19:00:00,547 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using NIO.
2023-08-23 19:00:00,548 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 38 ms).
2023-08-23 19:00:00,552 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using NIO.
2023-08-23 19:00:00,596 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 46 ms). Listening on SocketAddress /127.0.0.1:50988.
2023-08-23 19:00:00,598 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2023-08-23 19:00:00,628 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-08-23 19:00:00,646 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2023-08-23 19:00:00,647 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /var/folders/x1/pr8c20ks4vqgjl0bv5_h2ss00000gn/T/flink-dist-cache-e916cd32-00e3-4e14-943f-463ea677c066
2023-08-23 19:00:00,650 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2023-08-23 19:00:00,849 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2023-08-23 19:00:00,922 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 03897a6b9adb17b8575370d16c1ff081.
2023-08-23 20:18:31,226 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 4bba804a5102a7b47e59bf1abeeb5b63 for job db2f767aaccf7b573651e5e617d7a2b6 from resource manager with leader id 00000000000000000000000000000000.
2023-08-23 20:18:31,245 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,247 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job db2f767aaccf7b573651e5e617d7a2b6 for job leader monitoring.
2023-08-23 20:18:31,249 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2023-08-23 20:18:31,279 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2023-08-23 20:18:31,296 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job db2f767aaccf7b573651e5e617d7a2b6.
2023-08-23 20:18:31,298 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job db2f767aaccf7b573651e5e617d7a2b6.
2023-08-23 20:18:31,301 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job db2f767aaccf7b573651e5e617d7a2b6.
2023-08-23 20:18:31,348 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,378 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2023-08-23 20:18:31,391 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id db2f767aaccf7b573651e5e617d7a2b6
2023-08-23 20:18:31,407 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,408 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2023-08-23 20:18:31,409 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,411 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2023-08-23 20:18:31,411 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,412 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,412 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
2023-08-23 20:18:31,413 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
2023-08-23 20:18:31,419 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading db2f767aaccf7b573651e5e617d7a2b6/p-0379782ccb7bce36a6a1c6a8656651d9c894ac0a-5983df99cd50108480a9bbacca7b6ced from localhost/127.0.0.1:50984
2023-08-23 20:18:31,439 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task ProcessingTimeSessionWindows -> Sink: Print to Std. Out (1/1)#0 (21444205d0aebab77f92007df414bbbf_8b481b930a189b6b1762a9d95a61ada1_0_0), deploy into slot with allocation id 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,439 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - ProcessingTimeSessionWindows -> Sink: Print to Std. Out (1/1)#0 (21444205d0aebab77f92007df414bbbf_8b481b930a189b6b1762a9d95a61ada1_0_0) switched from CREATED to DEPLOYING.
2023-08-23 20:18:31,440 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4bba804a5102a7b47e59bf1abeeb5b63.
2023-08-23 20:18:31,440 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task ProcessingTimeSessionWindows -> Sink: Print to Std. Out (1/1)#0 (21444205d0aebab77f92007df414bbbf_8b481b930a189b6b1762a9d95a61ada1_0_0) [DEPLOYING].
2023-08-23 20:18:31,707 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6b2c336
2023-08-23 20:18:31,707 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2023-08-23 20:18:31,710 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2023-08-23 20:18:31,726 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@b6e4ad4
2023-08-23 20:18:31,726 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@30f019ea
2023-08-23 20:18:31,726 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2023-08-23 20:18:31,726 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2023-08-23 20:18:31,726 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2023-08-23 20:18:31,726 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2023-08-23 20:18:31,739 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - ProcessingTimeSessionWindows -> Sink: Print to Std. Out (1/1)#0 (21444205d0aebab77f92007df414bbbf_8b481b930a189b6b1762a9d95a61ada1_0_0) switched from DEPLOYING to INITIALIZING.
2023-08-23 20:18:31,740 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2023-08-23 20:18:31,740 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
2023-08-23 20:18:31,936 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackendBuilder [] - Finished to build heap keyed state-backend.
2023-08-23 20:18:31,944 INFO  org.apache.flink.runtime.state.heap.HeapKeyedStateBackend    [] - Initializing heap keyed state backend with stream factory.
2023-08-23 20:18:31,975 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - ProcessingTimeSessionWindows -> Sink: Print to Std. Out (1/1)#0 (21444205d0aebab77f92007df414bbbf_8b481b930a189b6b1762a9d95a61ada1_0_0) switched from INITIALIZING to RUNNING.
2023-08-23 20:18:31,992 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2023-08-23 20:18:31,992 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2023-08-23 20:18:32,016 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-acosom-flink-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acosom-flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-08-23 20:18:32,016 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-acosom-flink-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acosom-flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-08-23 20:18:32,176 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2023-08-23 20:18:32,177 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2023-08-23 20:18:32,177 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1692814712175
2023-08-23 20:18:32,183 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2023-08-23 20:18:32,183 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2023-08-23 20:18:32,183 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1692814712175
2023-08-23 20:18:32,460 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-2, groupId=acosom-flink-consumer-group] Cluster ID: 7VU22fxUS72liPXVyu8LLA
2023-08-23 20:18:32,460 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-1, groupId=acosom-flink-consumer-group] Cluster ID: 7VU22fxUS72liPXVyu8LLA
2023-08-23 20:18:32,463 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='user.interaction.data', partition=0}]
2023-08-23 20:18:32,463 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='user.information.data', partition=0}]
2023-08-23 20:18:32,464 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2023-08-23 20:18:32,464 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map (1/1)#0 (21444205d0aebab77f92007df414bbbf_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
2023-08-23 20:18:32,467 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='user.information.data', partition=0}=-915623761773}.
2023-08-23 20:18:32,467 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='user.interaction.data', partition=0}=-915623761773}.
2023-08-23 20:18:32,476 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-acosom-flink-consumer-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acosom-flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-08-23 20:18:32,476 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-acosom-flink-consumer-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acosom-flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1692814712486
2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2023-08-23 20:18:32,486 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1692814712486
2023-08-23 20:18:32,488 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Subscribed to partition(s): user.information.data-0
2023-08-23 20:18:32,488 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Subscribed to partition(s): user.interaction.data-0
2023-08-23 20:18:32,505 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Resetting the last seen epoch of partition user.interaction.data-0 to 0 since the associated topicId changed from null to ujx_Ta2RRqu9410yEwAxbg
2023-08-23 20:18:32,505 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Resetting the last seen epoch of partition user.information.data-0 to 0 since the associated topicId changed from null to _ytI6vgdQIWcNGwcWKlW4w
2023-08-23 20:18:32,505 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Cluster ID: 7VU22fxUS72liPXVyu8LLA
2023-08-23 20:18:32,505 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Cluster ID: 7VU22fxUS72liPXVyu8LLA
2023-08-23 20:18:32,506 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
2023-08-23 20:18:32,506 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
2023-08-23 20:18:32,518 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Found no committed offset for partition user.interaction.data-0
2023-08-23 20:18:32,518 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Found no committed offset for partition user.information.data-0
2023-08-23 20:18:32,531 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Resetting offset for partition user.information.data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.
2023-08-23 20:18:32,531 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Resetting offset for partition user.interaction.data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1001 rack: null)], epoch=0}}.
2023-08-23 20:27:32,628 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Node -1 disconnected.
2023-08-23 20:27:32,628 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Node -1 disconnected.
2023-08-23 20:47:46,393 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 20:47:46,393 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 20:47:46,753 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 1717 due to node 1001 being disconnected (elapsed time since creation: 962094ms, elapsed time since send: 962094ms, request timeout: 30000ms)
2023-08-23 20:47:46,754 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 1716 due to node 1001 being disconnected (elapsed time since creation: 962094ms, elapsed time since send: 962094ms, request timeout: 30000ms)
2023-08-23 20:47:46,761 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=1739987101, epoch=1558) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 20:47:46,760 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=1012158747, epoch=1557) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 20:47:46,957 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Node 2147482646 disconnected.
2023-08-23 20:47:46,957 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Node 2147482646 disconnected.
2023-08-23 20:47:46,959 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Group coordinator localhost:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
2023-08-23 20:47:46,959 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Group coordinator localhost:9092 (id: 2147482646 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
2023-08-23 20:47:46,959 WARN  org.apache.flink.streaming.connectors.kafka.internals.KafkaFetcher [] - Committing offsets to Kafka failed. This does not compromise Flink's checkpoints.
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException
2023-08-23 20:47:46,959 WARN  org.apache.flink.streaming.connectors.kafka.internals.KafkaFetcher [] - Committing offsets to Kafka failed. This does not compromise Flink's checkpoints.
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException
2023-08-23 20:47:46,960 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 failed async Kafka commit.
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException
2023-08-23 20:47:46,960 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 failed async Kafka commit.
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException
2023-08-23 20:47:51,627 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
2023-08-23 20:47:52,121 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Discovered group coordinator localhost:9092 (id: 2147482646 rack: null)
2023-08-23 21:23:59,846 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 21:23:59,845 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 21:24:00,217 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 6137 due to node 1001 being disconnected (elapsed time since creation: 157492ms, elapsed time since send: 157492ms, request timeout: 30000ms)
2023-08-23 21:24:00,217 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 6136 due to node 1001 being disconnected (elapsed time since creation: 157342ms, elapsed time since send: 157342ms, request timeout: 30000ms)
2023-08-23 21:24:00,217 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=707596460, epoch=4005) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 21:24:00,217 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=248851193, epoch=4005) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 21:44:23,607 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 21:44:23,608 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Disconnecting from node 1001 due to request timeout.
2023-08-23 21:44:23,950 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 7750 due to node 1001 being disconnected (elapsed time since creation: 480059ms, elapsed time since send: 480059ms, request timeout: 30000ms)
2023-08-23 21:44:23,948 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Cancelled in-flight FETCH request with correlation id 7751 due to node 1001 being disconnected (elapsed time since creation: 480059ms, elapsed time since send: 480059ms, request timeout: 30000ms)
2023-08-23 21:44:23,973 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-4, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=240645015, epoch=1461) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 21:44:23,973 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-acosom-flink-consumer-group-3, groupId=acosom-flink-consumer-group] Error sending fetch request (sessionId=1033818294, epoch=1461) to node 1001:
org.apache.kafka.common.errors.DisconnectException: null
2023-08-23 21:45:15,267 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2023-08-23 21:45:15,269 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2023-08-23 21:45:15,269 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2023-08-23 21:45:15,270 INFO  org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager [] - Shutting down TaskExecutorStateChangelogStoragesManager.
2023-08-23 21:45:15,271 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2023-08-23 21:45:15,277 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopping TaskExecutor akka.tcp://flink@localhost:50986/user/rpc/taskmanager_0.
2023-08-23 21:45:15,419 INFO  akka.actor.CoordinatedShutdown                               [] - Running CoordinatedShutdown with reason [ActorSystemTerminateReason]
2023-08-23 21:45:15,429 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Shutting down remote daemon.
2023-08-23 21:45:15,429 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Shutting down remote daemon.
2023-08-23 21:45:15,431 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remote daemon shut down; proceeding with flushing remote transports.
2023-08-23 21:45:15,431 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remote daemon shut down; proceeding with flushing remote transports.
2023-08-23 21:45:15,455 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remoting shut down.
2023-08-23 21:45:15,455 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remoting shut down.
